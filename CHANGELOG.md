# Changelog

All notable changes to Engram will be documented in this file.

## [1.0.0] - 2026-02-04

### ğŸ‰ Major Release: Production-Ready Semantic Memory

This is a **major milestone** release with three complete phases of semantic embedding integration.

### Added

#### Phase 1: Default Semantic Embedding
- âœ¨ **Multilingual semantic search by default** (`paraphrase-multilingual-MiniLM-L12-v2`)
- ğŸŒ **50+ languages supported** including Chinese, English, Spanish, French, German, Japanese, etc.
- âš¡ **Fast vector generation** (~250 memories/sec on CPU)
- ğŸ”„ **Migration script** (`migrate_vectors.py`) for existing databases
- ğŸ“Š **Cross-language recall** - Query in English, find Chinese memories (and vice versa)

#### Phase 2: Configuration System
- ğŸ›ï¸ **Environment variable configuration** (`ENGRAM_EMBEDDING`)
- ğŸ”Œ **Multiple provider support**: Sentence Transformers, Ollama, OpenAI, FTS5-only
- ğŸ› ï¸ **Custom model support** (`ENGRAM_ST_MODEL`, `ENGRAM_OLLAMA_MODEL`)
- ğŸ“¡ **New MCP tool**: `embedding_status` (query current provider and config)
- ğŸ” **Graceful error handling** with fallback to FTS5

#### Phase 3: Auto-Fallback Chain
- ğŸ¤– **Zero-config deployment** - Auto-detects best available provider
- ğŸ”„ **Priority chain**: Ollama â†’ Sentence Transformers â†’ OpenAI â†’ FTS5
- ğŸ“ˆ **Enhanced status tool** with available providers detection
- ğŸ“ **Comprehensive logging** to `/tmp/engram-mcp-debug.log`
- ğŸ§ª **Full test coverage** for all fallback scenarios

### Changed

- ğŸ“¦ **Package name**: Keeping `engramai` for PyPI compatibility
- ğŸ¯ **Default mode**: Auto-detection (`ENGRAM_EMBEDDING=auto`)
- ğŸ“š **Complete documentation rewrite** with installation guides

### Performance

- Model size: 118MB (Sentence Transformers, one-time download)
- Startup time: ~200ms (after first download)
- Vector generation: ~250 mem/sec (M2 CPU)
- Search latency: 10-50ms (1000 memories)
- Cross-language accuracy: 100% (tested: ä¸­æ–‡ â†” English)

### Breaking Changes

**None** - Fully backward compatible! 

- Existing databases work without migration (auto-fallback to FTS5 if no embedding installed)
- Previous `ENGRAM_EMBEDDING` values still work
- No API changes to Python or MCP interface

### Migration Guide

#### For New Users
```bash
# Just install with semantic search support
pip install "engramai[sentence-transformers]"
```

#### For Existing Users (0.3.x â†’ 1.0.0)
```bash
# 1. Update package
pip install --upgrade "engramai[sentence-transformers]"

# 2. Optional: Generate vectors for existing memories
cd /path/to/engram-ai
python3 migrate_vectors.py --db-path /path/to/your.db

# Done! Zero config changes needed.
```

### Documentation

- [Embedding Configuration Guide](engram/EMBEDDING-CONFIG.md)
- [Phase 1-2 Summary](PHASE1-2-SUMMARY.md)
- [Phase 3 Complete Report](PHASE3-COMPLETE.md)
- [Updated README](README.md)

### Contributors

- @tonitangpotato

---

## [0.3.1] - Previous Release

Session-aware working memory and performance optimizations.

See Git history for details.
